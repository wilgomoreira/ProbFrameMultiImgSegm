{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SegNet\n",
      " Num class: 7 \n",
      " Input chanels: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.segnet import SegNet\n",
    "num_classes  = 7\n",
    "rgb_channels = 3\n",
    "model = SegNet( num_classes, \n",
    "                n_init_features = rgb_channels,\n",
    "                )\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFORESTDataset\n",
      " Loaded 230 Files\n",
      " Target size: [240, 240]\n",
      " Loading mode: DISK\n"
     ]
    }
   ],
   "source": [
    "from dataloaders.FREIBRG import MFORESTDataset\n",
    "from dataloaders.FREIBRG import  conv_mask_to_img_np\n",
    "root = \"C:/Users/kunha/Desktop/src/\"  # path to the root directory of the dataset \n",
    "\n",
    "test_loader = MFORESTDataset( root=root,\n",
    "                        set='test',\n",
    "                        rgb_dir = 'rgb',\n",
    "                        mask_dir = 'GT_color',\n",
    "                        dsm_dir = 'depth_gray',\n",
    "                        num_classes = 7 \n",
    "\n",
    "                        )\n",
    "train_loader = MFORESTDataset( root=root,\n",
    "                        set='train',\n",
    "                        rgb_dir = 'rgb',\n",
    "                        mask_dir = 'GT_color',\n",
    "                        dsm_dir = 'depth_gray',\n",
    "                        num_classes = 7 \n",
    "\n",
    "                        )\n",
    "print(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of images in a training set is:  231\n",
      "231\n",
      "138\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 3\n",
    "train_dataloader = DataLoader(train_loader, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_loader, batch_size=batch_size, shuffle=True)\n",
    "print(\"The number of images in a training set is: \", len(train_dataloader)*batch_size)\n",
    "print(len(train_dataloader)*batch_size)\n",
    "print(len(test_dataloader)*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 92 instances\n",
      "Validation set has 23 instances\n"
     ]
    }
   ],
   "source": [
    "TrainingSIZE =int(len(train_dataloader) *0.8)\n",
    "ValidationSIZE =int(len(train_dataloader) - TrainingSIZE)\n",
    "training_data, validation_data = torch.utils.data.random_split(train_dataloader, [TrainingSIZE, ValidationSIZE])\n",
    "print('Training set has {} instances'.format(len(training_data)))\n",
    "print('Validation set has {} instances'.format(len(validation_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "# Function to save the model\n",
    "def saveModel():\n",
    "    path = \"./Modelo1.pth\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "# Function to test the model with the test dataset and print the accuracy for the test images\n",
    "def testAccuracy():\n",
    "    \n",
    "    model.eval()\n",
    "    accuracy = 0\n",
    "    total = 0\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            rgb,dsm,mask,id = data\n",
    "            rgb, mask = rgb.to(device), mask.to(device)\n",
    "            #rgb, mask = rgb.cuda(), mask.cuda()\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = model(rgb)\n",
    "            outputsnp = outputs.cpu()\n",
    "            outputsnp = np.asarray(outputs)\n",
    "            outputst = tf.convert_to_tensor(outputsnp)\n",
    "            #outputs  = torch.stack(outputs, dim=0)\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputst, 1)\n",
    "            total += mask.size(0)\n",
    "            accuracy += (predicted == mask).sum().item()\n",
    "    \n",
    "    # compute the accuracy over all test images\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return(accuracy)\n",
    "\n",
    "\n",
    "# Training function. We simply have to loop over our data iterator and feed the inputs to the network and optimize.\n",
    "def train(num_epochs):\n",
    "    best_accuracy = 0\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #device = torch.device(\"cpu\")\n",
    "\n",
    "    print(\"The model will be running on\", device, \"device\")\n",
    "    \n",
    "    # Convert model parameters and buffers to CPU or Cuda\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0\n",
    "        running_acc = 0\n",
    "\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            rgb,dsm,mask,id = data\n",
    "            #rgb.to(device)\n",
    "            #rgb, mask = rgb.cuda(), mask.cuda()\n",
    "            rgb, mask = rgb.to(device), mask.to(device)\n",
    "            \n",
    "            #mask = torch.argmax(mask,axis=1,keepdim=True)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # predict classes using images from the training set\n",
    "            outputs,_ = model(rgb)\n",
    "            #outputs = torch.argmax(outputs,axis=1,keepdim=True)\n",
    "\n",
    "            # compute the loss based on model output and real labels\n",
    "            loss = loss_fn(outputs, mask)\n",
    "            # backpropagate the loss\n",
    "            loss.backward()\n",
    "            # adjust parameters based on the calculated gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # Let's print statistics for every 1,000 images\n",
    "            running_loss += loss.item()     # extract the loss value\n",
    "            if i % 1000 == 999:    \n",
    "                # print every 1000 (twice per epoch) \n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 1000))\n",
    "                # zero the loss\n",
    "                running_loss = 0\n",
    "\n",
    "        # Compute and print the average accuracy fo this epoch when tested over all 10000 test images\n",
    "        accuracy = testAccuracy()\n",
    "        print('For epoch', epoch+1,'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
    "        \n",
    "        # we want to save the model if the accuracy is the best\n",
    "        if accuracy > best_accuracy:\n",
    "            saveModel()\n",
    "            best_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be running on cuda:0 device\n",
      "Epoch: 1 \tTraining Loss: 0.290555\n",
      "Epoch: 2 \tTraining Loss: 0.180146\n",
      "Epoch: 3 \tTraining Loss: 0.149599\n",
      "Epoch: 4 \tTraining Loss: 0.144095\n",
      "Epoch: 5 \tTraining Loss: 0.130931\n",
      "Epoch: 6 \tTraining Loss: 0.129230\n",
      "Epoch: 7 \tTraining Loss: 0.121925\n",
      "Epoch: 8 \tTraining Loss: 0.125693\n"
     ]
    }
   ],
   "source": [
    "num_epochs=8\n",
    "\n",
    "# keeping-track-of-losses \n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"The model will be running on\", device, \"device\")\n",
    "    \n",
    "# Convert model parameters and buffers to CPU or Cuda\n",
    "model.to(device)\n",
    "best_accuracy = 0\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # keep-track-of-training-and-validation-loss\n",
    "    train_loss = 0.0\n",
    "    #valid_loss = 0.0\n",
    "    \n",
    "    # training-the-model\n",
    "    model.train()\n",
    "    for data in train_dataloader:\n",
    "        rgb,dsm,mask,id = data\n",
    "        rgb, mask = rgb.to(device), mask.to(device)\n",
    "\n",
    "        \n",
    "        # clear-the-gradients-of-all-optimized-variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward-pass: compute-predicted-outputs-by-passing-inputs-to-the-model\n",
    "        output,_ = model(rgb)\n",
    "        # calculate-the-batch-loss\n",
    "        loss = loss_fn(output, mask)\n",
    "        # backward-pass: compute-gradient-of-the-loss-wrt-model-parameters\n",
    "        loss.backward()\n",
    "        # perform-a-ingle-optimization-step (parameter-update)\n",
    "        optimizer.step()\n",
    "        # update-training-loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    \"\"\"\n",
    "    # validate-the-model\n",
    "    model.eval()\n",
    "    #accuracy = 0\n",
    "    total = 0\n",
    "    for data in test_dataloader:\n",
    "        rgb,dsm,mask,id = data\n",
    "        rgb, mask = rgb.to(device), mask.to(device)\n",
    "        \n",
    "        output,_ = model(rgb)\n",
    "        #_, predicted = torch.max(output, 1)\n",
    "        #total += mask.size(0)\n",
    "        #accuracy += (predicted == mask).sum().item()\n",
    "        loss = loss_fn(output, mask)\n",
    "        \n",
    "        # update-average-validation-loss \n",
    "        valid_loss += loss.item()\n",
    "    \"\"\"\n",
    "    # calculate-average-losses\n",
    "    train_loss = train_loss/len(train_dataloader.sampler)\n",
    "    #valid_loss = valid_loss/len(test_dataloader.sampler)\n",
    "    train_losses.append(train_loss)\n",
    "    #valid_losses.append(valid_loss)\n",
    "        \n",
    "    # print-training/validation-statistics \n",
    "    #print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "     #   epoch, train_loss, valid_loss))\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "\n",
    "    #print('For epoch', epoch+1,'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
    "            \n",
    "    #if accuracy > best_accuracy:\n",
    "     #   saveModel()\n",
    "     #   best_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoints/Model_8epochs.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model: 579613.9705882353 %\n"
     ]
    }
   ],
   "source": [
    "# test-the-model\n",
    "#classes = ('void','Road','Grass','Vegetation','Tree','Sky','Obstacle')\n",
    "#correct_pred = {classname: 0 for classname in classes}\n",
    "#total_pred = {classname: 0 for classname in classes}\n",
    "model.eval()  # it-disables-dropout\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in test_dataloader:\n",
    "        rgb,dsm,mask,id = data\n",
    "        rgb = rgb.to(device)\n",
    "        mask = mask.to(device)\n",
    "        outputs,_ = model(rgb)\n",
    "        #outputs = torch.tensor(outputs)\n",
    "        #outputs  = torch.stack(outputs, dim=0)\n",
    "        #predicted,_ = torch.max(outputs.data,dim=1,keepdim=True)\n",
    "        _, predicted = torch.max(outputs, 1,keepdim=True)\n",
    "        total += mask.size(0)\n",
    "        correct += (predicted == mask).sum().item()\n",
    "          \n",
    "    print('Test Accuracy of the model: {} %'.format(100 * correct / total))\n",
    "\n",
    "\n",
    "# Save \n",
    "#path = os.path.join('checkpoints') import os\n",
    "torch.save(model.state_dict(), 'checkpoints/Modelo1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_pixels = 0\n",
    "    dice_score = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            rgb,dsm,mask,id = data\n",
    "            rgb,mask = rgb.to(device), mask.to(device)\n",
    "            softmax = nn.Softmax(dim=1)\n",
    "            outputs,_ = model(rgb)\n",
    "            preds = torch.argmax(softmax(outputs),axis=1,keepdim=True)\n",
    "            num_correct += (preds == mask).sum()\n",
    "            num_pixels += torch.numel(preds)\n",
    "            dice_score += (2 * (preds * mask).sum()) / ((preds + mask).sum() + 1e-8)\n",
    "\n",
    "    print(f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\")\n",
    "    print(f\"Dice score: {dice_score/len(loader)}\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1329848/13248000 with acc 10.04\n",
      "Dice score: 0.2767717242240906\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(train_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 761294/7833600 with acc 9.72\n",
      "Dice score: 0.2768886387348175\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(test_dataloader, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63d44262996451cf37b5e5f5dd7a7aa7e98f7e5c32d58716b2b89215e74a5278"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
